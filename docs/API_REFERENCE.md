# crlLwTT API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

> **å®Œå…¨ãªAPIãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** - å…¨ã‚¯ãƒ©ã‚¹ã€ãƒ¡ã‚½ãƒƒãƒ‰ã€è¨­å®šã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®è©³ç´°ä»•æ§˜

## ğŸ“– ç›®æ¬¡

- [åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª](#åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª)
- [ã‚³ã‚¢ã‚¯ãƒ©ã‚¹](#ã‚³ã‚¢ã‚¯ãƒ©ã‚¹)
- [æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«](#æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«)
- [ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£](#ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£)
- [è¨­å®šã¨åˆæœŸåŒ–](#è¨­å®šã¨åˆæœŸåŒ–)
- [ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)

---

## ğŸš€ åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

### LwTT åå‰ç©ºé–“

```cpp
namespace crllwtt {
    // åˆæœŸåŒ–ãƒ»çµ‚äº†å‡¦ç†
    bool Initialize(const GlobalConfig& config = GlobalConfig{});
    void Cleanup();
    
    // ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    std::string GetVersion();
    std::string GetBuildInfo();
    
    // ãƒ­ã‚°è¨­å®š
    void SetLogLevel(LogLevel level);
    void EnableFileLogging(const std::string& filename);
}
```

### åˆæœŸåŒ–è¨­å®š

```cpp
struct GlobalConfig {
    // ä¸¦åˆ—å‡¦ç†è¨­å®š
    int num_threads = -1;                    // -1ã§è‡ªå‹•æ¤œå‡º
    bool enable_openmp = true;               // OpenMPä½¿ç”¨
    
    // ãƒ¡ãƒ¢ãƒªè¨­å®š
    size_t memory_pool_size = 1024 * 1024 * 1024;  // 1GB
    bool enable_memory_pool = true;          // ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¼ãƒ«ä½¿ç”¨
    
    // æœ€é©åŒ–è¨­å®š
    bool enable_simd = true;                 // SIMDæœ€é©åŒ–
    bool enable_kernel_fusion = true;       // ã‚«ãƒ¼ãƒãƒ«èåˆ
    
    // ãƒ­ã‚°è¨­å®š
    LogLevel log_level = LogLevel::Info;
    std::string log_file = "";
};

enum class LogLevel {
    Debug, Info, Warning, Error, Critical
};
```

---

## ğŸ§  ã‚³ã‚¢ã‚¯ãƒ©ã‚¹

### 1. Tensor ã‚¯ãƒ©ã‚¹

**åŸºæœ¬ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œ**

```cpp
namespace crllwtt::Core {

class Tensor {
public:
    // ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
    Tensor();                                    // ç©ºãƒ†ãƒ³ã‚½ãƒ«
    Tensor(const std::vector<int>& shape);       // å½¢çŠ¶æŒ‡å®š
    Tensor(const std::vector<int>& shape, float value);  // åˆæœŸå€¤æŒ‡å®š
    Tensor(const Tensor& other);                 // ã‚³ãƒ”ãƒ¼ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
    Tensor(Tensor&& other);                      // ãƒ ãƒ¼ãƒ–ã‚³ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚¿
    
    // åŸºæœ¬ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    const std::vector<int>& GetShape() const;
    int GetSize() const;                         // ç·è¦ç´ æ•°
    int GetDimension() const;                    // æ¬¡å…ƒæ•°
    std::string ShapeString() const;             // å½¢çŠ¶æ–‡å­—åˆ—è¡¨ç¾
    
    // ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹
    float* GetData();                            // ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ã‚¿
    const float* GetData() const;
    float GetValue(const std::vector<int>& indices) const;
    void SetValue(const std::vector<int>& indices, float value);
    
    // å½¢çŠ¶æ“ä½œ
    void Resize(const std::vector<int>& new_shape);
    Tensor Reshape(const std::vector<int>& new_shape) const;
    Tensor Transpose(const std::vector<int>& axes = {}) const;
    Tensor Squeeze(int axis = -1) const;         // æ¬¡å…ƒå‰Šé™¤
    Tensor Unsqueeze(int axis) const;            // æ¬¡å…ƒè¿½åŠ 
    
    // æ•°å­¦æ¼”ç®—
    Tensor Add(const Tensor& other) const;       // è¦ç´ ã”ã¨åŠ ç®—
    Tensor Subtract(const Tensor& other) const;  // è¦ç´ ã”ã¨æ¸›ç®—
    Tensor Multiply(const Tensor& other) const;  // è¦ç´ ã”ã¨ä¹—ç®—
    Tensor Divide(const Tensor& other) const;    // è¦ç´ ã”ã¨é™¤ç®—
    Tensor MatMul(const Tensor& other) const;    // è¡Œåˆ—ä¹—ç®—
    
    // ã‚¹ã‚«ãƒ©ãƒ¼æ¼”ç®—
    Tensor MultiplyScalar(float scalar) const;
    Tensor AddScalar(float scalar) const;
    
    // çµ±è¨ˆé–¢æ•°
    float Sum() const;                           // å…¨è¦ç´ ã®å’Œ
    float Mean() const;                          // å¹³å‡å€¤
    float Max() const;                           // æœ€å¤§å€¤
    float Min() const;                           // æœ€å°å€¤
    float Norm() const;                          // ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰ãƒãƒ«ãƒ 
    
    // åˆæœŸåŒ–
    void Random(float min = 0.0f, float max = 1.0f);  // ä¹±æ•°åˆæœŸåŒ–
    void Zero();                                 // ã‚¼ãƒ­åˆæœŸåŒ–
    void Fill(float value);                      // å®šæ•°åˆæœŸåŒ–
    void Normal(float mean = 0.0f, float std = 1.0f); // æ­£è¦åˆ†å¸ƒåˆæœŸåŒ–
    
    // ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    bool IsEmpty() const;
    bool IsScalar() const;
    bool IsVector() const;
    bool IsMatrix() const;
    void Print(const std::string& name = "") const;
};

}
```

### 2. TransformerBuilder ã‚¯ãƒ©ã‚¹

**é«˜æ€§èƒ½Transformeræ§‹ç¯‰**

```cpp
namespace crllwtt::Core {

class TransformerBuilder {
public:
    TransformerBuilder();
    
    // ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­å®š
    TransformerBuilder& SetModelDimension(int d_model);
    TransformerBuilder& SetNumHeads(int num_heads);
    TransformerBuilder& SetNumLayers(int num_layers);
    TransformerBuilder& SetMaxSequenceLength(int max_seq_len);
    TransformerBuilder& SetFeedForwardDim(int ff_dim);
    
    // æœ€é©åŒ–è¨­å®š
    TransformerBuilder& EnableSparseAttention(bool enable, float sparsity_ratio = 0.1f);
    TransformerBuilder& EnableTimeAwareness(bool enable, float delay_compensation = 0.0f);
    TransformerBuilder& EnableKernelFusion(bool enable);
    TransformerBuilder& SetMaxInferenceTime(float time_ms);
    
    // æ­£è¦åŒ–ãƒ»ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ
    TransformerBuilder& SetDropoutRate(float rate);
    TransformerBuilder& SetLayerNormEpsilon(float epsilon);
    TransformerBuilder& EnablePreNorm(bool enable);
    
    // ä¸¦åˆ—å‡¦ç†
    TransformerBuilder& SetNumThreads(int num_threads);
    TransformerBuilder& EnableAsyncExecution(bool enable);
    
    // é«˜åº¦ãªè¨­å®š
    TransformerBuilder& SetActivationFunction(ActivationType activation);
    TransformerBuilder& EnableGradientCheckpointing(bool enable);
    TransformerBuilder& SetPrecisionMode(PrecisionMode mode);
    
    // æ§‹ç¯‰
    std::unique_ptr<Transformer> Build();
    
private:
    TransformerConfig config_;
};

// è¨­å®šæ§‹é€ ä½“
struct TransformerConfig {
    // ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    int d_model = 512;
    int num_heads = 8;
    int num_layers = 6;
    int max_seq_len = 512;
    int ff_dim = 2048;
    
    // æœ€é©åŒ–
    bool enable_sparse_attention = false;
    float sparsity_ratio = 0.1f;
    bool enable_time_awareness = false;
    float delay_compensation = 0.0f;
    bool enable_kernel_fusion = true;
    float max_inference_time_ms = 10.0f;
    
    // æ­£è¦åŒ–
    float dropout_rate = 0.1f;
    float layer_norm_epsilon = 1e-5f;
    bool use_pre_norm = true;
    
    // ä¸¦åˆ—å‡¦ç†
    int num_threads = -1;
    bool async_execution = false;
    
    // é«˜åº¦ãªè¨­å®š
    ActivationType activation = ActivationType::GELU;
    bool gradient_checkpointing = false;
    PrecisionMode precision = PrecisionMode::FP32;
};

enum class ActivationType { ReLU, GELU, Swish, Tanh, Sigmoid };
enum class PrecisionMode { FP32, FP16, INT8, MIXED };

}
```

### 3. Transformer ã‚¯ãƒ©ã‚¹

**ãƒ¡ã‚¤ãƒ³Transformerãƒ¢ãƒ‡ãƒ«**

```cpp
namespace crllwtt::Core {

class Transformer {
public:
    explicit Transformer(const TransformerConfig& config);
    virtual ~Transformer();
    
    // æ¨è«–
    Tensor Forward(const Tensor& input, 
                  const Tensor* attention_mask = nullptr,
                  const TimeEncodingInfo* time_info = nullptr,
                  int person_id = -1);
    
    // ãƒãƒƒãƒæ¨è«–
    std::vector<Tensor> ForwardBatch(const std::vector<Tensor>& inputs,
                                   const std::vector<Tensor*>& masks = {},
                                   const std::vector<TimeEncodingInfo*>& time_infos = {},
                                   const std::vector<int>& person_ids = {});
    
    // ä¸ç¢ºå®Ÿæ€§ä»˜ãæ¨è«–
    std::pair<Tensor, Tensor> ForwardWithUncertainty(
        const Tensor& input,
        const Tensor* attention_mask = nullptr,
        const TimeEncodingInfo* time_info = nullptr,
        int num_samples = 10);
    
    // ãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—äºˆæ¸¬
    Tensor PredictMultiStep(const Tensor& input, int num_steps);
    
    // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ¨è«–
    Tensor ForwardStreaming(const Tensor& new_input,
                          bool is_first_chunk = false,
                          bool is_last_chunk = false);
    
    // ãƒ¢ãƒ‡ãƒ«æƒ…å ±
    const TransformerConfig& GetConfig() const;
    size_t GetParameterCount() const;
    size_t GetMemoryUsage() const;
    
    // æœ€é©åŒ–
    void OptimizeForInference(int optimization_level = 1);
    void EnableBenchmarkMode(bool enable);
    
    // çµ±è¨ˆ
    struct InferenceStats {
        float last_inference_time_ms;
        float average_inference_time_ms;
        size_t total_inferences;
        float cache_hit_ratio;
        size_t peak_memory_usage;
    };
    
    InferenceStats GetInferenceStats() const;
    void ResetStats();
    
    // ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆé«˜åº¦ãªç”¨é€”ï¼‰
    std::vector<Tensor> GetParameters() const;
    void SetParameters(const std::vector<Tensor>& parameters);
    
    // ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿
    void SaveModel(const std::string& filepath) const;
    void LoadModel(const std::string& filepath);
    
private:
    class TransformerImpl;
    std::unique_ptr<TransformerImpl> impl_;
};

}
```

### 4. STATransformer ã‚¯ãƒ©ã‚¹

**ç’°å¢ƒåˆ¶å¾¡å°‚ç”¨ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**

```cpp
namespace crllwtt::Core {

class STATransformer {
public:
    explicit STATransformer(const STAConfig& config);
    virtual ~STATransformer();
    
    // çŠ¶æ…‹äºˆæ¸¬
    Tensor PredictState(const Tensor& observable_state,
                       const Tensor& control_input,
                       const TimeEncodingInfo* time_info = nullptr,
                       int person_id = -1);
    
    // ä¸ç¢ºå®Ÿæ€§ä»˜ãäºˆæ¸¬
    std::pair<Tensor, Tensor> PredictWithUncertainty(
        const Tensor& observable_state,
        const Tensor& control_input,
        const TimeEncodingInfo* time_info = nullptr,
        int person_id = -1,
        int num_samples = 5);
    
    // æœ€é©åˆ¶å¾¡è¨ˆç®—
    Tensor ComputeOptimalControl(const Tensor& observable_state,
                               const Tensor& current_control,
                               const Tensor& target_state,
                               float control_constraint = 1.0f);
    
    // æ„Ÿåº¦è§£æ
    Tensor ComputeSensitivity(const Tensor& observable_state,
                            const Tensor& control_input,
                            int output_dim = -1);
    
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å­¦ç¿’
    void UpdateModel(const Tensor& observable_state,
                    const Tensor& control_input,
                    const Tensor& actual_state,
                    float learning_rate = -1.0f);
    
    // å€‹äººé©å¿œ
    void AdaptToUser(int person_id, 
                    const std::vector<Tensor>& user_data,
                    const std::vector<Tensor>& user_responses);
    
    // åˆ¶å¾¡çµ±è¨ˆ
    struct ControlStats {
        float control_effectiveness;    // åˆ¶å¾¡åŠ¹æœ (0-1)
        float prediction_accuracy;      // äºˆæ¸¬ç²¾åº¦
        float adaptation_speed;         // é©å¿œé€Ÿåº¦
        int num_updates;               // æ›´æ–°å›æ•°
        float average_response_time_ms; // å¹³å‡å¿œç­”æ™‚é–“
    };
    
    ControlStats GetControlStats() const;
    
    // è¨­å®š
    const STAConfig& GetConfig() const;
    void SetTargetResponseTime(float time_ms);
    void EnablePersonalAdaptation(bool enable);
    
private:
    class STATransformerImpl;
    std::unique_ptr<STATransformerImpl> impl_;
};

// STAè¨­å®š
struct STAConfig {
    // å…¥å‡ºåŠ›æ¬¡å…ƒ
    int observable_state_dim = 8;      // è¦³æ¸¬å¯èƒ½çŠ¶æ…‹æ¬¡å…ƒ
    int controllable_input_dim = 4;    // åˆ¶å¾¡å¯èƒ½å…¥åŠ›æ¬¡å…ƒ  
    int predicted_state_dim = 4;       // äºˆæ¸¬çŠ¶æ…‹æ¬¡å…ƒ
    
    // ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
    int d_model = 256;
    int num_heads = 8;
    int num_layers = 4;
    int max_seq_len = 128;
    
    // å­¦ç¿’è¨­å®š
    float learning_rate = 0.001f;
    float control_gain = 0.1f;
    bool enable_uncertainty = true;
    int ensemble_size = 3;
    
    // å€‹äººåŒ–
    bool enable_personal_adaptation = true;
    int personal_embed_dim = 32;
    
    // åˆ¶ç´„
    float max_response_time_ms = 1.0f;
    float control_smoothness = 0.1f;
    
    // æœ€é©åŒ–
    bool enable_sparse_attention = true;
    float sparsity_ratio = 0.2f;
    bool enable_kernel_fusion = true;
};

}
```

### 5. AdaptiveGradient ã‚¯ãƒ©ã‚¹

**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‹¾é…è¨ˆç®—**

```cpp
namespace crllwtt::Core {

class AdaptiveGradient {
public:
    explicit AdaptiveGradient(const AdaptiveGradientConfig& config = {});
    
    // å‹¾é…è¨ˆç®—
    GradientResult ComputeGradient(
        std::function<Tensor(const std::vector<Tensor>&)> loss_function,
        const std::vector<Tensor>& parameters,
        float max_time_ms = -1.0f);
    
    // åå¾®åˆ†è¨ˆç®—
    GradientResult ComputePartialDerivative(
        std::function<Tensor(const Tensor&)> function,
        const Tensor& input,
        int output_idx = 0,
        float max_time_ms = -1.0f);
    
    // æ„Ÿåº¦è¨ˆç®—ï¼ˆSTAç”¨ï¼‰
    GradientResult ComputeSensitivity(
        std::function<Tensor(const Tensor&, const Tensor&)> state_predictor,
        const Tensor& observable_state,
        const Tensor& control_input,
        float max_time_ms = -1.0f);
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
    void CacheGradient(size_t input_hash, const Tensor& gradient, 
                      const GradientResult& computation_info);
    std::unique_ptr<GradientResult> GetCachedGradient(size_t input_hash) const;
    void ClearCache();
    
    // ç²¾åº¦é©å¿œ
    float AdaptPrecision(float available_time_ms) const;
    
    // çµ±è¨ˆ
    struct GradientStats {
        size_t total_computations;
        size_t cache_hits;
        size_t cache_misses;
        float average_computation_time_ms;
        float cache_hit_ratio;
        size_t numerical_fallbacks;
    };
    
    GradientStats GetStats() const;
    void ResetStats();
    
    // ãƒãƒƒãƒ•ã‚¡ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼è¨­å®š
    void SetBufferManager(std::shared_ptr<Utils::PreallocatedBuffers> buffers);
    
private:
    AdaptiveGradientConfig config_;
    // ... å†…éƒ¨å®Ÿè£…
};

// å‹¾é…è¨ˆç®—çµæœ
struct GradientResult {
    Tensor gradient;
    float computation_time_ms;
    float precision_achieved;
    bool used_cache;
    bool used_numerical;
    
    GradientResult();
};

// å‹¾é…è¨ˆç®—è¨­å®š
struct AdaptiveGradientConfig {
    float max_computation_time_ms = 1.0f;
    float precision_threshold = 1e-6f;
    int max_cache_size = 1000;
    bool enable_numerical_fallback = true;
    bool enable_gradient_clipping = true;
    float gradient_clip_value = 1.0f;
    bool enable_adaptive_precision = true;
};

}
```

---

## âš¡ æœ€é©åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

### 1. SparseAttention ã‚¯ãƒ©ã‚¹

**åŠ¹ç‡çš„ã‚¹ãƒ‘ãƒ¼ã‚¹æ³¨æ„æ©Ÿæ§‹**

```cpp
namespace crllwtt::Core {

class SparseAttention {
public:
    explicit SparseAttention(const SparseAttentionConfig& config = {});
    
    // ã‚¹ãƒ‘ãƒ¼ã‚¹æ³¨æ„è¨ˆç®—
    Tensor Forward(const Tensor& query,
                  const Tensor& key,
                  const Tensor& value,
                  const Tensor* mask = nullptr);
    
    // ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒã‚¹ã‚¯ç”Ÿæˆ
    Tensor CreateSparseMask(int seq_len, SparsePatternType pattern_type = SparsePatternType::Adaptive);
    
    // è¨­å®š
    void SetSparsityRatio(float ratio);
    float GetSparsityRatio() const;
    void SetAdaptiveSparsity(bool enable);
    const SparseAttentionConfig& GetConfig() const;
    
private:
    SparseAttentionConfig config_;
    bool adaptive_sparsity_ = true;
    
    // å†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰
    Tensor ComputeAttentionScores(const Tensor& query, const Tensor& key);
    Tensor ApplySparsityMask(const Tensor& attention_scores, const Tensor& mask);
    Tensor ComputeAdaptiveMask(const Tensor& attention_scores);
    Tensor CreateLocalWindowMask(int seq_len);
    Tensor CreateBlockSparseMask(int seq_len);
};

// ã‚¹ãƒ‘ãƒ¼ã‚¹æ³¨æ„è¨­å®š
struct SparseAttentionConfig {
    float sparsity_ratio = 0.1f;        // ã‚¹ãƒ‘ãƒ¼ã‚¹ç‡
    int block_size = 64;                 // ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º
    bool use_random_sparsity = false;    // ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ãƒ‘ãƒ¼ã‚¹æ€§
    bool use_local_attention = true;     // ãƒ­ãƒ¼ã‚«ãƒ«æ³¨æ„
    int local_window_size = 128;         // ãƒ­ãƒ¼ã‚«ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
};

// ã‚¹ãƒ‘ãƒ¼ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—
enum class SparsePatternType {
    Random,         // ãƒ©ãƒ³ãƒ€ãƒ ã‚¹ãƒ‘ãƒ¼ã‚¹
    Structured,     // æ§‹é€ åŒ–ã‚¹ãƒ‘ãƒ¼ã‚¹
    LocalWindow,    // ãƒ­ãƒ¼ã‚«ãƒ«ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦
    BlockSparse,    // ãƒ–ãƒ­ãƒƒã‚¯ã‚¹ãƒ‘ãƒ¼ã‚¹
    Adaptive        // é©å¿œçš„ã‚¹ãƒ‘ãƒ¼ã‚¹
};

// ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
namespace SparseAttentionUtils {
    float ComputeSparsity(const Tensor& attention_weights);
    Tensor CreateStridedMask(int seq_len, int stride);
    Tensor OptimizeSparsityPattern(const Tensor& query, const Tensor& key, float target_sparsity);
}

}
```

### 2. KernelFusion ã‚¯ãƒ©ã‚¹

**æ¼”ç®—å­èåˆæœ€é©åŒ–**

```cpp
namespace crllwtt::Optimization {

class KernelFusion {
public:
    explicit KernelFusion(const KernelFusionConfig& config = {});
    
    // èåˆæ¼”ç®—
    Tensor FusedLinearReLU(const Tensor& input, 
                          const Tensor& weight, 
                          const Tensor& bias);
    
    Tensor FusedAttentionSoftmax(const Tensor& query,
                                const Tensor& key,
                                const Tensor& value,
                                const Tensor* mask = nullptr,
                                float scale = 1.0f);
    
    Tensor FusedLayerNormReLU(const Tensor& input,
                             const Tensor& gamma,
                             const Tensor& beta,
                             float epsilon = 1e-5f);
    
    Tensor FusedGELUDropout(const Tensor& input, 
                           float dropout_rate = 0.1f,
                           bool training = true);
    
    // è¨ˆç®—ã‚°ãƒ©ãƒ•æœ€é©åŒ–
    void OptimizeComputationGraph(const std::vector<Operation>& operations);
    
    // çµ±è¨ˆ
    struct OptimizationStats {
        int total_operations = 0;
        int fused_operations = 0;
        int single_operations = 0;
        float fusion_ratio = 0.0f;
        float estimated_speedup = 1.0f;
    };
    
    OptimizationStats GetOptimizationStats() const;
    const std::vector<FusedOperation>& GetFusedOperations() const;
    
    // é™çš„ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    static Tensor MatMulBiasActivation(const Tensor& input,
                                      const Tensor& weight,
                                      const Tensor& bias,
                                      ActivationType activation = ActivationType::None);
    
    Tensor FusedTransformerBlock(const Tensor& input,
                                const TransformerBlockParams& params);
    
private:
    KernelFusionConfig config_;
    std::vector<FusedOperation> fused_operations_;
};

// ã‚«ãƒ¼ãƒãƒ«èåˆè¨­å®š
struct KernelFusionConfig {
    bool enable_linear_relu_fusion = true;
    bool enable_attention_fusion = true;
    bool enable_layernorm_fusion = true;
    bool enable_gelu_dropout_fusion = true;
    bool enable_transformer_block_fusion = true;
    float fusion_threshold = 0.1f;
};

// æ¼”ç®—ã‚¿ã‚¤ãƒ—
enum class OperationType {
    Linear, ReLU, GELU, Tanh, Sigmoid, LayerNorm, Attention, Dropout, Softmax
};

enum class FusedOperationType {
    LinearReLU, LayerNormReLU, GELUDropout, AttentionSoftmax, TransformerBlock, Single
};

// é«˜ãƒ¬ãƒ™ãƒ«èåˆãƒ‘ã‚¿ãƒ¼ãƒ³
namespace FusionPatterns {
    Tensor FusedMultiHeadAttention(const Tensor& input, /* ... */);
    Tensor FusedFeedForward(const Tensor& input, /* ... */);
    Tensor FusedResidualLayerNorm(const Tensor& input, /* ... */);
}

}
```

---

## ğŸ› ï¸ ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

### 1. SIMDUtils ã‚¯ãƒ©ã‚¹

**SIMDæœ€é©åŒ–ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£**

```cpp
namespace crllwtt::Utils {

class SIMDUtils {
public:
    // SIMDæƒ…å ±
    static const int kSIMDWidth;
    static std::string GetSIMDInfo();
    static bool IsSIMDSupported();
    static int GetOptimalAlignment();
    
    // ãƒ™ã‚¯ãƒˆãƒ«æ¼”ç®—
    static void VectorAdd(const float* a, const float* b, float* result, int size);
    static void VectorMul(const float* a, const float* b, float* result, int size);
    static float DotProduct(const float* a, const float* b, int size);
    static void VectorScale(const float* input, float scale, float* output, int size);
    
    // è¡Œåˆ—æ¼”ç®—
    static void MatrixMultiply(const float* a, const float* b, float* c,
                              int m, int n, int k,
                              bool transpose_a = false, bool transpose_b = false);
    
    // æ´»æ€§åŒ–é–¢æ•°
    static void ApplyActivation(const float* input, float* output, int size, ActivationType activation);
    static void SoftMax(const float* input, float* output, int size);
    
private:
    SIMDUtils() = delete; // é™çš„ã‚¯ãƒ©ã‚¹
};

// SIMDå¯¾å¿œã‚¢ãƒ­ã‚±ãƒ¼ã‚¿ãƒ¼
class SIMDAllocator {
public:
    static float* AllocateAligned(size_t size);
    static void FreeAligned(float* ptr);
    static bool IsAligned(const void* ptr);
};

}
```

### 2. PreallocatedBuffers ã‚¯ãƒ©ã‚¹

**ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç®¡ç†**

```cpp
namespace crllwtt::Utils {

class PreallocatedBuffers {
public:
    explicit PreallocatedBuffers(const BufferPoolConfig& config = {});
    ~PreallocatedBuffers();
    
    // ãƒ†ãƒ³ã‚½ãƒ«ç®¡ç†
    Tensor GetWorkTensor(const std::vector<int>& shape);
    void ReturnWorkTensor(Tensor&& tensor);
    Tensor GetAttentionBuffer(int seq_len, int num_heads);
    
    // å‹¾é…ç®¡ç†
    void StoreGradient(const Tensor& gradient, const std::string& param_name);
    Tensor GetCachedGradient(const std::string& param_name, size_t offset = 0) const;
    
    // ãƒ¢ãƒ‡ãƒ«å›ºæœ‰äº‹å‰å‰²ã‚Šå½“ã¦
    void PreallocateForModel(int max_seq_len, int d_model, int num_heads, int num_layers);
    
    // çµ±è¨ˆ
    struct MemoryStats {
        size_t total_allocated_mb;
        size_t tensor_pool_usage_mb;
        size_t gradient_buffer_usage_mb;
        size_t attention_buffer_usage_mb;
        double memory_efficiency;
    };
    
    MemoryStats GetMemoryStats() const;
    void Reset();
    void SetRealTimeMode(bool enable);
    
private:
    BufferPoolConfig config_;
    // ... å†…éƒ¨å®Ÿè£…
};

// ãƒãƒƒãƒ•ã‚¡ãƒ—ãƒ¼ãƒ«è¨­å®š
struct BufferPoolConfig {
    size_t max_tensor_size = 1024 * 1024;  // 1MB
    size_t tensor_pool_size = 16;
    size_t gradient_buffer_size = 512;
    size_t attention_buffer_size = 256;
    bool enable_simd_alignment = true;
    size_t alignment = 32;
};

// RAIIãƒ˜ãƒ«ãƒ‘ãƒ¼
class ScopedTensor {
public:
    ScopedTensor(Tensor&& tensor, PreallocatedBuffers* buffers);
    ~ScopedTensor();
    
    Tensor& operator*();
    const Tensor& operator*() const;
    Tensor* operator->();
    const Tensor* operator->() const;
    
private:
    Tensor tensor_;
    PreallocatedBuffers* buffers_;
};

}
```

### 3. TimeEncoding ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

**æ™‚é–“èªè­˜ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**

```cpp
namespace crllwtt::Core {

// æ™‚é–“æƒ…å ±æ§‹é€ ä½“
struct TimeEncodingInfo {
    std::vector<float> timestamps;      // ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    float personal_delay = 0.0f;        // å€‹äººé…å»¶
    float temporal_scale = 1.0f;        // æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«
    bool enable_multiscale = true;      // ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«æœ‰åŠ¹
    
    TimeEncodingInfo() = default;
    TimeEncodingInfo(const std::vector<float>& ts, float delay = 0.0f);
};

// æ™‚é–“ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
namespace TimeEncodingUtils {
    
    // æ™‚é–“æƒ…å ±ä½œæˆ
    TimeEncodingInfo CreateTimeInfo(const std::vector<float>& timestamps, 
                                   float personal_delay = 0.0f);
    
    // æ™‚é–“ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¨ˆç®—
    Tensor ComputeTimeEncoding(const TimeEncodingInfo& time_info, 
                              int seq_len, int d_model);
    
    // ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«æ™‚é–“ç‰¹å¾´
    Tensor ComputeMultiscaleTimeFeatures(const std::vector<float>& timestamps,
                                        const std::vector<float>& scales);
    
    // å€‹äººé…å»¶è£œå„Ÿ
    std::vector<float> ApplyDelayCompensation(const std::vector<float>& timestamps,
                                            float personal_delay);
    
    // æ™‚é–“ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    struct TemporalPattern {
        float dominant_frequency;
        float periodicity_strength;
        std::vector<float> harmonic_components;
    };
    
    TemporalPattern AnalyzeTemporalPattern(const std::vector<float>& timestamps);
    
    // é©å¿œçš„æ™‚é–“ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
    Tensor AdaptiveTimeEncoding(const TimeEncodingInfo& time_info,
                               const TemporalPattern& pattern,
                               int d_model);
}

}
```

---

## âš™ï¸ è¨­å®šã¨åˆæœŸåŒ–

### ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š

```cpp
namespace crllwtt {

// ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
struct PerformanceConfig {
    // ä¸¦åˆ—å‡¦ç†
    int num_threads = -1;               // -1ã§è‡ªå‹•æ¤œå‡º
    bool enable_openmp = true;
    bool enable_async_execution = false;
    
    // SIMDè¨­å®š
    bool enable_simd = true;
    bool force_simd_alignment = true;
    
    // ãƒ¡ãƒ¢ãƒªè¨­å®š
    size_t memory_pool_size = 1GB;
    bool enable_memory_prefetch = true;
    bool enable_numa_optimization = false;
    
    // ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
    size_t attention_cache_size = 100MB;
    size_t gradient_cache_size = 50MB;
    bool enable_computation_cache = true;
};

// ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°è¨­å®š
struct ProfilingConfig {
    bool enable_timing = false;
    bool enable_memory_tracking = false;
    bool enable_cache_statistics = false;
    std::string profile_output_file = "";
    int profile_sampling_rate = 1000;  // Hz
};

// ãƒ‡ãƒãƒƒã‚°è¨­å®š
struct DebugConfig {
    LogLevel log_level = LogLevel::Info;
    bool enable_assertions = true;
    bool enable_nan_checking = false;
    bool enable_bounds_checking = false;
    std::string debug_output_dir = "./debug";
};

// å®Œå…¨ãªåˆæœŸåŒ–
bool Initialize(const PerformanceConfig& perf_config = {},
               const ProfilingConfig& prof_config = {},
               const DebugConfig& debug_config = {});

}
```

### ç’°å¢ƒå¤‰æ•°

```bash
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é–¢é€£
export LWTT_NUM_THREADS=8
export LWTT_ENABLE_SIMD=1
export LWTT_MEMORY_POOL_SIZE=2048M

# æœ€é©åŒ–é–¢é€£
export LWTT_ENABLE_SPARSE_ATTENTION=1
export LWTT_SPARSITY_RATIO=0.1
export LWTT_ENABLE_KERNEL_FUSION=1

# ãƒ‡ãƒãƒƒã‚°é–¢é€£
export LWTT_LOG_LEVEL=INFO
export LWTT_ENABLE_PROFILING=0
export LWTT_DEBUG_OUTPUT_DIR=./logs
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ä¾‹å¤–ã‚¯ãƒ©ã‚¹

```cpp
namespace crllwtt {

// åŸºåº•ä¾‹å¤–ã‚¯ãƒ©ã‚¹
class LwTTException : public std::exception {
public:
    explicit LwTTException(const std::string& message);
    const char* what() const noexcept override;
    
protected:
    std::string message_;
};

// å…·ä½“çš„ãªä¾‹å¤–ã‚¯ãƒ©ã‚¹
class InvalidShapeException : public LwTTException {
public:
    InvalidShapeException(const std::vector<int>& expected, 
                         const std::vector<int>& actual);
};

class ComputationTimeoutException : public LwTTException {
public:
    ComputationTimeoutException(float timeout_ms, float actual_ms);
};

class MemoryAllocationException : public LwTTException {
public:
    MemoryAllocationException(size_t requested_bytes);
};

class ModelLoadException : public LwTTException {
public:
    ModelLoadException(const std::string& filepath, const std::string& reason);
};

class ConfigurationException : public LwTTException {
public:
    ConfigurationException(const std::string& parameter, const std::string& issue);
};

}
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```cpp
#include <LwTT/LwTT.hpp>

int main() {
    try {
        // ãƒ©ã‚¤ãƒ–ãƒ©ãƒªåˆæœŸåŒ–
        if (!LwTT::Initialize()) {
            std::cerr << "LwTTåˆæœŸåŒ–å¤±æ•—" << std::endl;
            return -1;
        }
        
        // ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
        auto transformer = LwTT::Core::TransformerBuilder()
            .SetModelDimension(256)
            .SetNumHeads(8)
            .SetMaxInferenceTime(1.0f)  // 1msåˆ¶ç´„
            .Build();
        
        // æ¨è«–å®Ÿè¡Œ
        LwTT::Core::Tensor input({1, 100, 256});
        input.Random();
        
        auto output = transformer->Forward(input);
        
        std::cout << "æ¨è«–æˆåŠŸ" << std::endl;
        
    } catch (const LwTT::ComputationTimeoutException& e) {
        std::cerr << "è¨ˆç®—æ™‚é–“è¶…é: " << e.what() << std::endl;
    } catch (const LwTT::InvalidShapeException& e) {
        std::cerr << "å½¢çŠ¶ã‚¨ãƒ©ãƒ¼: " << e.what() << std::endl;
    } catch (const LwTT::LwTTException& e) {
        std::cerr << "LwTTã‚¨ãƒ©ãƒ¼: " << e.what() << std::endl;
    } catch (const std::exception& e) {
        std::cerr << "ä¸€èˆ¬ã‚¨ãƒ©ãƒ¼: " << e.what() << std::endl;
    }
    
    LwTT::Cleanup();
    return 0;
}
```

---

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ç”¨API

```cpp
namespace crllwtt::Benchmark {

class PerformanceMonitor {
public:
    // ã‚¿ã‚¤ãƒãƒ¼
    void StartTimer(const std::string& name);
    void StopTimer(const std::string& name);
    float GetElapsedTime(const std::string& name) const;
    
    // ãƒ¡ãƒ¢ãƒªç›£è¦–
    size_t GetCurrentMemoryUsage() const;
    size_t GetPeakMemoryUsage() const;
    void ResetMemoryStats();
    
    // çµ±è¨ˆå–å¾—
    struct BenchmarkStats {
        std::map<std::string, float> timing_stats;
        size_t current_memory_mb;
        size_t peak_memory_mb;
        float cpu_utilization;
        float cache_hit_ratio;
    };
    
    BenchmarkStats GetStats() const;
    void ExportStats(const std::string& filename) const;
    
    // ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
    void EnableDetailedProfiling(bool enable);
    void SetSamplingRate(int hz);
    
private:
    // å†…éƒ¨å®Ÿè£…
};

// ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‹ã‚¿ãƒ¼
extern PerformanceMonitor g_performance_monitor;

// RAIIã‚¿ã‚¤ãƒãƒ¼
class ScopedTimer {
public:
    explicit ScopedTimer(const std::string& name);
    ~ScopedTimer();
    
private:
    std::string name_;
};

// ãƒã‚¯ãƒ­
#define LWTT_PROFILE_SCOPE(name) ScopedTimer _timer(name)
#define LWTT_PROFILE_FUNCTION() LWTT_PROFILE_SCOPE(__FUNCTION__)

}
```

---

ã“ã®APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã«ã‚ˆã‚Šã€crlLwTTãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®å…¨æ©Ÿèƒ½ã‚’åŠ¹ç‡çš„ã«æ´»ç”¨ã§ãã¾ã™ã€‚å„ã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ãªä½¿ç”¨æ–¹æ³•ã«ã¤ã„ã¦ã¯ã€å¯¾å¿œã™ã‚‹ãƒ˜ãƒƒãƒ€ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚³ãƒ¡ãƒ³ãƒˆã‚‚å‚ç…§ã—ã¦ãã ã•ã„ã€‚