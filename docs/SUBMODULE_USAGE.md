# crlLwTT Submoduleä½¿ç”¨ã‚¬ã‚¤ãƒ‰

## æ¦‚è¦

crlLwTTã¯è»½é‡ãªTransformerãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ä»–ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®submoduleã¨ã—ã¦åŠ¹ç‡çš„ã«åˆ©ç”¨ã§ãã¾ã™ã€‚ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€submoduleã¨ã—ã¦ã®å°å…¥ã¨åˆ©ç”¨æ–¹æ³•ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¾ã™ã€‚

## ç‰¹å¾´

### ğŸš€ é«˜é€ŸåŒ–ã•ã‚ŒãŸSubmoduleãƒ“ãƒ«ãƒ‰

- **é¸æŠçš„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ**: å¿…è¦ãªæ©Ÿèƒ½ã®ã¿ãƒ“ãƒ«ãƒ‰
- **ç°¡ç•¥åŒ–ã•ã‚ŒãŸä¾å­˜é–¢ä¿‚**: è»½é‡ãªæ§‹æˆã§é«˜é€Ÿãƒ“ãƒ«ãƒ‰
- **è‡ªå‹•æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ **: ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨submoduleã‚’è‡ªå‹•åˆ¤åˆ¥

### ğŸ“¦ æœ€é©åŒ–ã•ã‚ŒãŸãƒ“ãƒ«ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | Submodule | èª¬æ˜ |
|---|---|---|---|
| `LWTT_BUILD_TESTS` | ON | OFF | ãƒ†ã‚¹ãƒˆãƒ»ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ |
| `LWTT_BUILD_DOCS` | ON | OFF | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç”Ÿæˆ |
| `LWTT_BUILD_PYTHON_BINDINGS` | ON | OFF | Python ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚° |
| `LWTT_BUILD_SHARED` | ON | OFF | å…±æœ‰ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| `LWTT_BUILD_STATIC` | ON | ON | é™çš„ãƒ©ã‚¤ãƒ–ãƒ©ãƒª |
| `LWTT_INSTALL` | ON | OFF | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«è¨­å®š |

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### 1. Submoduleã¨ã—ã¦è¿½åŠ 

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã§å®Ÿè¡Œ
git submodule add https://github.com/your-org/crlLwTT.git external/crlLwTT
git submodule update --init --recursive
```

### 2. CMakeLists.txtã«è¿½åŠ 

```cmake
cmake_minimum_required(VERSION 3.16)
project(YourProject VERSION 1.0.0 LANGUAGES CXX)

# C++23æ¨™æº–ã‚’è¨­å®š
set(CMAKE_CXX_STANDARD 23)
set(CMAKE_CXX_STANDARD_REQUIRED ON)

# crlLwTT submoduleã‚’è¿½åŠ 
add_subdirectory(external/crlLwTT)

# ã‚ãªãŸã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
add_executable(your_app src/main.cpp)

# LwTTã¨ãƒªãƒ³ã‚¯
target_link_libraries(your_app PRIVATE LwTT)
```

### 3. åŸºæœ¬çš„ãªC++ä½¿ç”¨ä¾‹

```cpp
#include <LwTT/core/Tensor.hpp>
#include <LwTT/layers/Attention.hpp>
#include <LwTT/models/Transformer.hpp>

int main() {
    // Transformerãƒ¢ãƒ‡ãƒ«è¨­å®š
    LwTT::ModelConfig config;
    config.sequence_length = 512;
    config.hidden_size = 768;
    config.num_heads = 12;
    config.num_layers = 6;
    
    // ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    LwTT::Transformer model(config);
    
    // å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«ä½œæˆ
    auto input = LwTT::Tensor::randn({1, 512, 768});
    
    // æ¨è«–å®Ÿè¡Œ
    auto output = model.forward(input);
    
    std::cout << "Output shape: " << output.shape() << std::endl;
    return 0;
}
```

## ä¾å­˜é–¢ä¿‚ã®ç®¡ç†

### æœ€å°æ§‹æˆï¼ˆæ¨å¥¨ï¼‰

```cmake
# å¿…è¦æœ€å°é™ã®è¨­å®š
option(LWTT_USE_EIGEN "Use Eigen for linear algebra" ON)
option(LWTT_ENABLE_OPENMP "Enable OpenMP" ON)
option(LWTT_ENABLE_SIMD "Enable SIMD optimizations" ON)

add_subdirectory(external/crlLwTT)
```

### æ©Ÿèƒ½æ‹¡å¼µæ§‹æˆ

```cmake
# é«˜æ©Ÿèƒ½è¨­å®š
option(LWTT_ENABLE_QUANTIZATION "Enable quantization support" ON)
option(LWTT_ENABLE_PROFILING "Enable profiling" ON)

# PyTorchã¨ã®é€£æº
find_package(Torch QUIET)
if(Torch_FOUND)
    set(LWTT_HAS_TORCH TRUE)
endif()

add_subdirectory(external/crlLwTT)
```

## é«˜åº¦ãªä½¿ç”¨ä¾‹

### ã‚«ã‚¹ã‚¿ãƒ Attentionãƒ¬ã‚¤ãƒ¤ãƒ¼

```cpp
#include <LwTT/layers/MultiHeadAttention.hpp>

class CustomAttention : public LwTT::MultiHeadAttention {
public:
    CustomAttention(int hidden_size, int num_heads) 
        : MultiHeadAttention(hidden_size, num_heads) {}
    
    LwTT::Tensor forward(const LwTT::Tensor& input) override {
        // ã‚«ã‚¹ã‚¿ãƒ å®Ÿè£…
        auto qkv = compute_qkv(input);
        auto attention_weights = scaled_dot_product_attention(qkv);
        return apply_output_projection(attention_weights);
    }
};
```

### æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿å‡¦ç†

```cpp
#include <LwTT/core/TimeAwareProcessor.hpp>

int main() {
    // æ™‚ç³»åˆ—èªè­˜è¨­å®š
    LwTT::TimeConfig time_config;
    time_config.enable_temporal_encoding = true;
    time_config.max_sequence_length = 1024;
    
    LwTT::TimeAwareProcessor processor(time_config);
    
    // æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†
    auto time_series = LwTT::Tensor::from_vector(your_data);
    auto processed = processor.encode_temporal_features(time_series);
    
    return 0;
}
```

## ãƒ“ãƒ«ãƒ‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### ä¸¦åˆ—ãƒ“ãƒ«ãƒ‰

```bash
# ä¸¦åˆ—æ•°ã‚’æŒ‡å®šã—ã¦ãƒ“ãƒ«ãƒ‰
cmake --build build --parallel 8
```

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨

```bash
# ccacheã‚’ä½¿ç”¨ã—ã¦é«˜é€ŸåŒ–
export CMAKE_CXX_COMPILER_LAUNCHER=ccache
cmake -B build
cmake --build build
```

### æ®µéšçš„ãƒ“ãƒ«ãƒ‰

```cmake
# æ®µéšçš„ã«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’æœ‰åŠ¹åŒ–
if(ENABLE_ADVANCED_FEATURES)
    set(LWTT_ENABLE_QUANTIZATION ON)
    set(LWTT_ENABLE_PROFILING ON)
endif()
```

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œ

#### 1. ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼

```bash
# EigenãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
sudo apt-get install libeigen3-dev  # Ubuntu/Debian
brew install eigen                   # macOS
```

#### 2. ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼

```bash
# C++23å¯¾å¿œã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ãŒå¿…è¦
# GCC 11+, Clang 14+, MSVC 19.29+
```

#### 3. LibTorchã¨ã®ç«¶åˆ

```cmake
# LibTorchã‚’å„ªå…ˆçš„ã«æ¤œç´¢
find_package(Torch REQUIRED)
set(LWTT_HAS_TORCH TRUE)
```

### ãƒ‡ãƒãƒƒã‚°ãƒ“ãƒ«ãƒ‰

```cmake
# ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’æœ‰åŠ¹åŒ–
set(CMAKE_BUILD_TYPE Debug)
set(LWTT_ENABLE_PROFILING ON)
```

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ

| æ§‹æˆ | åˆå›ãƒ“ãƒ«ãƒ‰æ™‚é–“ | å¢—åˆ†ãƒ“ãƒ«ãƒ‰æ™‚é–“ | ãƒã‚¤ãƒŠãƒªã‚µã‚¤ã‚º |
|---|---|---|---|
| ãƒ•ãƒ«æ©Ÿèƒ½ | ~5åˆ† | ~30ç§’ | ~50MB |
| Submoduleæœ€é©åŒ– | ~2åˆ† | ~10ç§’ | ~15MB |
| æœ€å°æ§‹æˆ | ~1åˆ† | ~5ç§’ | ~8MB |

## æ›´æ–°ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### Submoduleã®æ›´æ–°

```bash
# æœ€æ–°ç‰ˆã«æ›´æ–°
git submodule update --remote external/crlLwTT

# ç‰¹å®šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å›ºå®š
cd external/crlLwTT
git checkout v1.2.0
cd ../..
git add external/crlLwTT
git commit -m "Update crlLwTT to v1.2.0"
```

### è¨­å®šã®ç¢ºèª

```bash
# CMakeè¨­å®šã®è¡¨ç¤º
cmake -B build -DCMAKE_BUILD_TYPE=Release
# ãƒ“ãƒ«ãƒ‰å¾Œã€è¨­å®šã‚µãƒãƒªãƒ¼ãŒè¡¨ç¤ºã•ã‚Œã¾ã™
```

## ã‚µãƒãƒ¼ãƒˆã¨ãƒªã‚½ãƒ¼ã‚¹

- **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒšãƒ¼ã‚¸**: [crlLwTT Repository]
- **API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: `docs/api/`
- **ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰**: `examples/`
- **èª²é¡Œå ±å‘Š**: GitHub Issues

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã§crlLwTTã‚’åŠ¹ç‡çš„ã«submoduleã¨ã—ã¦æ´»ç”¨ã—ã€é«˜æ€§èƒ½ãªTransformerãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã—ã¦ãã ã•ã„ï¼
